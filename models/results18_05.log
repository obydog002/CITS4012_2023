total models: 1920
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
skipping at load.
Starting load...
load 33/64
Starting batch load...
batch 33/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 17h 2m 31s
Starting training model...
train 963/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 10h 1m 10s
Starting training model...
train 965/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 55m 20s
Starting training model...
train 966/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 13m 58s
Starting training model...
train 968/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 55m 0s
Starting training model...
train 969/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 8h 18m 32s
Starting training model...
train 971/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 53m 51s
Starting training model...
train 972/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 35m 32s
Starting training model...
train 974/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 52m 42s
Starting training model...
train 975/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 8h 5m 19s
Starting training model...
train 977/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 51m 21s
Starting training model...
train 978/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 39m 22s
Starting training model...
train 980/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 50m 4s
Starting training model...
train 981/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 58m 36s
Starting training model...
train 983/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 48m 52s
Starting training model...
train 984/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 40m 11s
Starting training model...
train 986/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 47m 45s
Starting training model...
train 987/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 56m 55s
Starting training model...
train 989/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 49m 6s
Starting training model...
train 990/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 34/64
Starting batch load...
batch 34/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 36m 31s
Starting training model...
train 992/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 42m 0s
Starting training model...
train 993/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 46m 43s
Starting training model...
train 995/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 40m 17s
Starting training model...
train 996/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 34m 2s
Starting training model...
train 998/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 38m 36s
Starting training model...
train 999/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 42m 59s
Starting training model...
train 1001/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 37m 33s
Starting training model...
train 1002/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 32m 1s
Starting training model...
train 1004/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 36m 28s
Starting training model...
train 1005/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 40m 18s
Starting training model...
train 1007/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 35m 41s
Starting training model...
train 1008/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 30m 53s
Starting training model...
train 1010/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 34m 44s
Starting training model...
train 1011/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 37m 20s
Starting training model...
train 1013/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 33m 9s
Starting training model...
train 1014/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 28m 52s
Starting training model...
train 1016/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 31m 38s
Starting training model...
train 1017/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 33m 45s
Starting training model...
train 1019/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 30m 1s
Starting training model...
train 1020/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 35/64
Starting batch load...
batch 35/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 24m 1s
Starting training model...
train 1022/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 27m 13s
Starting training model...
train 1023/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 29m 3s
Starting training model...
train 1025/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 25m 43s
Starting training model...
train 1026/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 22m 3s
Starting training model...
train 1028/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 24m 29s
Starting training model...
train 1029/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 26m 24s
Starting training model...
train 1031/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 23m 21s
Starting training model...
train 1032/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 19m 59s
Starting training model...
train 1034/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 22m 18s
Starting training model...
train 1035/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 24m 3s
Starting training model...
train 1037/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 21m 14s
Starting training model...
train 1038/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 18m 3s
Starting training model...
train 1040/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 20m 7s
Starting training model...
train 1041/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 21m 39s
Starting training model...
train 1043/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 19m 0s
Starting training model...
train 1044/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 16m 0s
Starting training model...
train 1046/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 17m 34s
Starting training model...
train 1047/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 18m 37s
Starting training model...
train 1049/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 16m 9s
Starting training model...
train 1050/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 36/64
Starting batch load...
batch 36/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 10m 30s
Starting training model...
train 1052/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 11m 51s
Starting training model...
train 1053/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 12m 44s
Starting training model...
train 1055/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 10m 24s
Starting training model...
train 1056/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 7m 40s
Starting training model...
train 1058/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 8m 53s
Starting training model...
train 1059/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 9m 39s
Starting training model...
train 1061/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 7m 28s
Starting training model...
train 1062/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 4m 55s
Starting training model...
train 1064/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 6m 5s
Starting training model...
train 1065/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 6m 45s
Starting training model...
train 1067/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 4m 39s
Starting training model...
train 1068/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 2m 11s
Starting training model...
train 1070/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 3m 16s
Starting training model...
train 1071/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 3m 51s
Starting training model...
train 1073/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 1m 52s
Starting training model...
train 1074/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 59m 30s
Starting training model...
train 1076/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 0m 28s
Starting training model...
train 1077/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7h 0m 57s
Starting training model...
train 1079/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 59m 4s
Starting training model...
train 1080/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 37/64
Starting batch load...
batch 37/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 54m 43s
Starting training model...
train 1082/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 55m 39s
Starting training model...
train 1083/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 56m 7s
Starting training model...
train 1085/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 54m 20s
Starting training model...
train 1086/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 52m 9s
Starting training model...
train 1088/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 52m 59s
Starting training model...
train 1089/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 53m 24s
Starting training model...
train 1091/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 51m 43s
Starting training model...
train 1092/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('attention_type', 'Cosine'), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 49m 37s
Starting training model...
train 1094/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 50m 26s
Starting training model...
train 1095/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 50m 47s
Starting training model...
train 1097/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 49m 7s
Starting training model...
train 1098/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 47m 5s
Starting training model...
train 1100/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 47m 49s
Starting training model...
train 1101/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 48m 4s
Starting training model...
train 1103/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 46m 29s
Starting training model...
train 1104/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 44m 30s
Starting training model...
train 1106/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 45m 10s
Starting training model...
train 1107/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 45m 22s
Starting training model...
train 1109/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 43m 49s
Starting training model...
train 1110/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 38/64
Starting batch load...
batch 38/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 39m 21s
Starting training model...
train 1112/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 39m 57s
Starting training model...
train 1113/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 40m 4s
Starting training model...
train 1115/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 38m 37s
Starting training model...
train 1116/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 36m 41s
Starting training model...
train 1118/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 37m 14s
Starting training model...
train 1119/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 37m 20s
Starting training model...
train 1121/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 35m 53s
Starting training model...
train 1122/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('attention_type', 'Cosine'), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 34m 2s
Starting training model...
train 1124/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 34m 31s
Starting training model...
train 1125/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 34m 35s
Starting training model...
train 1127/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 33m 12s
Starting training model...
train 1128/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 31m 24s
Starting training model...
train 1130/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 31m 52s
Starting training model...
train 1131/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 31m 51s
Starting training model...
train 1133/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 30m 31s
Starting training model...
train 1134/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 28m 44s
Starting training model...
train 1136/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 29m 8s
Starting training model...
train 1137/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 29m 7s
Starting training model...
train 1139/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 27m 48s
Starting training model...
train 1140/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 39/64
Starting batch load...
batch 39/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 24m 0s
Starting training model...
train 1142/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 24m 24s
Starting training model...
train 1143/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 24m 20s
Starting training model...
train 1145/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 23m 3s
Starting training model...
train 1146/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 21m 22s
Starting training model...
train 1148/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 21m 44s
Starting training model...
train 1149/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 21m 39s
Starting training model...
train 1151/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 20m 25s
Starting training model...
train 1152/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('attention_type', 'Cosine'), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 18m 46s
Starting training model...
train 1154/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 19m 6s
Starting training model...
train 1155/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 19m 0s
Starting training model...
train 1157/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 17m 46s
Starting training model...
train 1158/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 16m 9s
Starting training model...
train 1160/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 16m 28s
Starting training model...
train 1161/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 16m 19s
Starting training model...
train 1163/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 15m 8s
Starting training model...
train 1164/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 13m 33s
Starting training model...
train 1166/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 13m 49s
Starting training model...
train 1167/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 13m 39s
Starting training model...
train 1169/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 12m 29s
Starting training model...
train 1170/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 40/64
Starting batch load...
batch 40/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 8m 31s
Starting training model...
train 1172/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 8m 46s
Starting training model...
train 1173/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 8m 35s
Starting training model...
train 1175/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 7m 27s
Starting training model...
train 1176/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 5m 54s
Starting training model...
train 1178/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 6m 7s
Starting training model...
train 1179/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 5m 54s
Starting training model...
train 1181/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 4m 47s
Starting training model...
train 1182/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('attention_type', 'Cosine'), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 3m 15s
Starting training model...
train 1184/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 3m 27s
Starting training model...
train 1185/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 3m 13s
Starting training model...
train 1187/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 2m 8s
Starting training model...
train 1188/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 0m 38s
Starting training model...
train 1190/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 0m 48s
Starting training model...
train 1191/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6h 0m 33s
Starting training model...
train 1193/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 59m 29s
Starting training model...
train 1194/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 58m 1s
Starting training model...
train 1196/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 58m 11s
Starting training model...
train 1197/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 57m 55s
Starting training model...
train 1199/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 56m 52s
Starting training model...
train 1200/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 41/64
Starting batch load...
batch 41/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 49m 31s
Starting training model...
train 1202/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 49m 40s
Starting training model...
train 1203/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 49m 22s
Starting training model...
train 1205/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 48m 20s
Starting training model...
train 1206/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 46m 54s
Starting training model...
train 1208/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 47m 1s
Starting training model...
train 1209/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 46m 43s
Starting training model...
train 1211/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 45m 44s
Starting training model...
train 1212/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 44m 18s
Starting training model...
train 1214/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 44m 25s
Starting training model...
train 1215/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 44m 6s
Starting training model...
train 1217/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 43m 7s
Starting training model...
train 1218/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 41m 42s
Starting training model...
train 1220/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 41m 49s
Starting training model...
train 1221/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 41m 27s
Starting training model...
train 1223/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 40m 29s
Starting training model...
train 1224/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 39m 6s
Starting training model...
train 1226/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 39m 11s
Starting training model...
train 1227/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 38m 48s
Starting training model...
train 1229/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 37m 51s
Starting training model...
train 1230/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 42/64
Starting batch load...
batch 42/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 31m 25s
Starting training model...
train 1232/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 31m 29s
Starting training model...
train 1233/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 31m 5s
Starting training model...
train 1235/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 30m 10s
Starting training model...
train 1236/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 28m 49s
Starting training model...
train 1238/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 28m 51s
Starting training model...
train 1239/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 28m 27s
Starting training model...
train 1241/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 27m 32s
Starting training model...
train 1242/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 26m 11s
Starting training model...
train 1244/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 26m 12s
Starting training model...
train 1245/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 25m 48s
Starting training model...
train 1247/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 24m 53s
Starting training model...
train 1248/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 23m 34s
Starting training model...
train 1250/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 23m 35s
Starting training model...
train 1251/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 23m 9s
Starting training model...
train 1253/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 22m 17s
Starting training model...
train 1254/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 20m 58s
Starting training model...
train 1256/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 20m 59s
Starting training model...
train 1257/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 20m 34s
Starting training model...
train 1259/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 19m 42s
Starting training model...
train 1260/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 43/64
Starting batch load...
batch 43/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 14m 26s
Starting training model...
train 1262/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 14m 26s
Starting training model...
train 1263/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 13m 59s
Starting training model...
train 1265/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 13m 7s
Starting training model...
train 1266/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 11m 51s
Starting training model...
train 1268/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 11m 50s
Starting training model...
train 1269/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 11m 23s
Starting training model...
train 1271/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 10m 32s
Starting training model...
train 1272/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 9m 16s
Starting training model...
train 1274/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 9m 14s
Starting training model...
train 1275/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 8m 46s
Starting training model...
train 1277/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 7m 57s
Starting training model...
train 1278/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 6m 42s
Starting training model...
train 1280/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 6m 39s
Starting training model...
train 1281/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 6m 11s
Starting training model...
train 1283/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 5m 22s
Starting training model...
train 1284/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 4m 8s
Starting training model...
train 1286/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 4m 5s
Starting training model...
train 1287/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 3m 35s
Starting training model...
train 1289/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5h 2m 47s
Starting training model...
train 1290/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 44/64
Starting batch load...
batch 44/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 57m 58s
Starting training model...
train 1292/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 57m 54s
Starting training model...
train 1293/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 57m 25s
Starting training model...
train 1295/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 56m 37s
Starting training model...
train 1296/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 55m 24s
Starting training model...
train 1298/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 55m 20s
Starting training model...
train 1299/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 54m 49s
Starting training model...
train 1301/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 54m 2s
Starting training model...
train 1302/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 52m 48s
Starting training model...
train 1304/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 52m 44s
Starting training model...
train 1305/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 52m 13s
Starting training model...
train 1307/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 51m 26s
Starting training model...
train 1308/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 50m 14s
Starting training model...
train 1310/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 50m 9s
Starting training model...
train 1311/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 49m 37s
Starting training model...
train 1313/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 48m 51s
Starting training model...
train 1314/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 47m 39s
Starting training model...
train 1316/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 47m 33s
Starting training model...
train 1317/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 47m 1s
Starting training model...
train 1319/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 46m 15s
Starting training model...
train 1320/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 45/64
Starting batch load...
batch 45/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 42m 7s
Starting training model...
train 1322/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 42m 1s
Starting training model...
train 1323/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 41m 30s
Starting training model...
train 1325/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 40m 44s
Starting training model...
train 1326/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 39m 34s
Starting training model...
train 1328/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 39m 28s
Starting training model...
train 1329/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 38m 56s
Starting training model...
train 1331/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 38m 11s
Starting training model...
train 1332/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('attention_type', 'Cosine'), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 37m 1s
Starting training model...
train 1334/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 36m 54s
Starting training model...
train 1335/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 36m 20s
Starting training model...
train 1337/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 35m 36s
Starting training model...
train 1338/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 34m 27s
Starting training model...
train 1340/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 34m 20s
Starting training model...
train 1341/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 33m 47s
Starting training model...
train 1343/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 33m 4s
Starting training model...
train 1344/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 31m 54s
Starting training model...
train 1346/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 31m 46s
Starting training model...
train 1347/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 31m 12s
Starting training model...
train 1349/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 30m 29s
Starting training model...
train 1350/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 46/64
Starting batch load...
batch 46/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 26m 36s
Starting training model...
train 1352/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 26m 28s
Starting training model...
train 1353/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 25m 53s
Starting training model...
train 1355/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 25m 10s
Starting training model...
train 1356/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 24m 2s
Starting training model...
train 1358/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 23m 54s
Starting training model...
train 1359/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 23m 19s
Starting training model...
train 1361/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 22m 36s
Starting training model...
train 1362/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('attention_type', 'Cosine'), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 21m 28s
Starting training model...
train 1364/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 21m 19s
Starting training model...
train 1365/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 20m 44s
Starting training model...
train 1367/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 20m 2s
Starting training model...
train 1368/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 18m 55s
Starting training model...
train 1370/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 18m 45s
Starting training model...
train 1371/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 18m 9s
Starting training model...
train 1373/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 17m 28s
Starting training model...
train 1374/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 16m 21s
Starting training model...
train 1376/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 16m 10s
Starting training model...
train 1377/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 15m 34s
Starting training model...
train 1379/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 14m 53s
Starting training model...
train 1380/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 47/64
Starting batch load...
batch 47/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 11m 30s
Starting training model...
train 1382/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 11m 20s
Starting training model...
train 1383/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 10m 43s
Starting training model...
train 1385/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 10m 2s
Starting training model...
train 1386/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 8m 56s
Starting training model...
train 1388/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 8m 44s
Starting training model...
train 1389/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 8m 7s
Starting training model...
train 1391/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 7m 26s
Starting training model...
train 1392/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('attention_type', 'Cosine'), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 6m 20s
Starting training model...
train 1394/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 6m 9s
Starting training model...
train 1395/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 5m 31s
Starting training model...
train 1397/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 4m 52s
Starting training model...
train 1398/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 3m 46s
Starting training model...
train 1400/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 3m 34s
Starting training model...
train 1401/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 2m 56s
Starting training model...
train 1403/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 2m 16s
Starting training model...
train 1404/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 1m 11s
Starting training model...
train 1406/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 0m 59s
Starting training model...
train 1407/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4h 0m 20s
Starting training model...
train 1409/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 59m 41s
Starting training model...
train 1410/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 48/64
Starting batch load...
batch 48/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 56m 27s
Starting training model...
train 1412/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 56m 15s
Starting training model...
train 1413/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 55m 37s
Starting training model...
train 1415/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 54m 58s
Starting training model...
train 1416/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 53m 53s
Starting training model...
train 1418/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 53m 40s
Starting training model...
train 1419/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 53m 1s
Starting training model...
train 1421/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 52m 23s
Starting training model...
train 1422/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('attention_type', 'Cosine'), ('q_cut_size', 'Max'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 51m 18s
Starting training model...
train 1424/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 51m 5s
Starting training model...
train 1425/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 50m 26s
Starting training model...
train 1427/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 49m 47s
Starting training model...
train 1428/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 48m 43s
Starting training model...
train 1430/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 48m 29s
Starting training model...
train 1431/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 47m 50s
Starting training model...
train 1433/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 47m 12s
Starting training model...
train 1434/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 46m 8s
Starting training model...
train 1436/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 45m 54s
Starting training model...
train 1437/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 45m 14s
Starting training model...
train 1439/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': True, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 44m 36s
Starting training model...
train 1440/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_tfidf', True), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 49/64
Starting batch load...
batch 49/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 43m 11s
Starting training model...
train 1442/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 42m 57s
Starting training model...
train 1443/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 42m 17s
Starting training model...
train 1445/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 41m 40s
Starting training model...
train 1446/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 40m 36s
Starting training model...
train 1448/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 40m 22s
Starting training model...
train 1449/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 39m 41s
Starting training model...
train 1451/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 39m 3s
Starting training model...
train 1452/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 38m 1s
Starting training model...
train 1454/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 37m 46s
Starting training model...
train 1455/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 37m 5s
Starting training model...
train 1457/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 36m 28s
Starting training model...
train 1458/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 35m 26s
Starting training model...
train 1460/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 35m 11s
Starting training model...
train 1461/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 34m 30s
Starting training model...
train 1463/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 33m 53s
Starting training model...
train 1464/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 32m 51s
Starting training model...
train 1466/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 32m 35s
Starting training model...
train 1467/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 31m 54s
Starting training model...
train 1469/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 31m 18s
Starting training model...
train 1470/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 50/64
Starting batch load...
batch 50/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 29m 38s
Starting training model...
train 1472/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 29m 23s
Starting training model...
train 1473/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 28m 42s
Starting training model...
train 1475/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 28m 6s
Starting training model...
train 1476/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 27m 4s
Starting training model...
train 1478/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 26m 48s
Starting training model...
train 1479/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 26m 6s
Starting training model...
train 1481/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 25m 31s
Starting training model...
train 1482/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('attention_type', 'Cosine'), ('q_with_ner', False), ('doc_hidden_layers', 1), ('befaft', False), ('hidden_size', 100), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 24m 29s
Starting training model...
train 1484/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('hidden_size', 100), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 24m 13s
Starting training model...
train 1485/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('hidden_size', 100), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 23m 32s
Starting training model...
train 1487/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('hidden_size', 100), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 22m 56s
Starting training model...
train 1488/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('hidden_size', 100), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 21m 55s
Starting training model...
train 1490/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 21m 39s
Starting training model...
train 1491/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 20m 56s
Starting training model...
train 1493/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 20m 21s
Starting training model...
train 1494/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 19m 20s
Starting training model...
train 1496/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 19m 4s
Starting training model...
train 1497/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 18m 21s
Starting training model...
train 1499/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 17m 46s
Starting training model...
train 1500/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('q_with_pos', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 51/64
Starting batch load...
batch 51/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 16m 4s
Starting training model...
train 1502/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 15m 47s
Starting training model...
train 1503/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 15m 4s
Starting training model...
train 1505/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 14m 29s
Starting training model...
train 1506/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 13m 28s
Starting training model...
train 1508/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 13m 12s
Starting training model...
train 1509/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 12m 29s
Starting training model...
train 1511/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 11m 54s
Starting training model...
train 1512/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 10m 53s
Starting training model...
train 1514/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 10m 36s
Starting training model...
train 1515/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 9m 53s
Starting training model...
train 1517/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 9m 18s
Starting training model...
train 1518/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 8m 18s
Starting training model...
train 1520/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 8m 1s
Starting training model...
train 1521/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 7m 18s
Starting training model...
train 1523/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 6m 43s
Starting training model...
train 1524/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 5m 43s
Starting training model...
train 1526/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 5m 26s
Starting training model...
train 1527/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 4m 42s
Starting training model...
train 1529/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 4m 8s
Starting training model...
train 1530/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 52/64
Starting batch load...
batch 52/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 2m 15s
Starting training model...
train 1532/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 1m 57s
Starting training model...
train 1533/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 1m 14s
Starting training model...
train 1535/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3h 0m 40s
Starting training model...
train 1536/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 59m 40s
Starting training model...
train 1538/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 59m 22s
Starting training model...
train 1539/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 58m 38s
Starting training model...
train 1541/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 58m 5s
Starting training model...
train 1542/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('attention_type', 'Cosine'), ('q_with_ner', False), ('doc_hidden_layers', 1), ('befaft', False), ('hidden_size', 100), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 57m 5s
Starting training model...
train 1544/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('hidden_size', 100), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 56m 47s
Starting training model...
train 1545/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('hidden_size', 100), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 56m 3s
Starting training model...
train 1547/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('hidden_size', 100), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 55m 30s
Starting training model...
train 1548/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('hidden_size', 100), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 54m 31s
Starting training model...
train 1550/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 54m 13s
Starting training model...
train 1551/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 53m 29s
Starting training model...
train 1553/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 52m 56s
Starting training model...
train 1554/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 51m 57s
Starting training model...
train 1556/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 51m 38s
Starting training model...
train 1557/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 50m 54s
Starting training model...
train 1559/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 50m 21s
Starting training model...
train 1560/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('hidden_type', 'RNN'), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 53/64
Starting batch load...
batch 53/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 48m 27s
Starting training model...
train 1562/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 48m 8s
Starting training model...
train 1563/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 47m 23s
Starting training model...
train 1565/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 46m 51s
Starting training model...
train 1566/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 45m 52s
Starting training model...
train 1568/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 45m 33s
Starting training model...
train 1569/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 44m 49s
Starting training model...
train 1571/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 44m 16s
Starting training model...
train 1572/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('attention_type', 'Cosine'), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 43m 18s
Starting training model...
train 1574/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 42m 59s
Starting training model...
train 1575/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 42m 13s
Starting training model...
train 1577/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 41m 41s
Starting training model...
train 1578/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 40m 43s
Starting training model...
train 1580/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 40m 23s
Starting training model...
train 1581/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 39m 38s
Starting training model...
train 1583/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 39m 6s
Starting training model...
train 1584/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 38m 8s
Starting training model...
train 1586/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 37m 48s
Starting training model...
train 1587/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 37m 3s
Starting training model...
train 1589/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 36m 31s
Starting training model...
train 1590/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 54/64
Starting batch load...
batch 54/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 34m 28s
Starting training model...
train 1592/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 34m 8s
Starting training model...
train 1593/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 33m 23s
Starting training model...
train 1595/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 32m 51s
Starting training model...
train 1596/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 31m 53s
Starting training model...
train 1598/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 31m 33s
Starting training model...
train 1599/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 30m 48s
Starting training model...
train 1601/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 30m 16s
Starting training model...
train 1602/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('attention_type', 'Cosine'), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 29m 18s
Starting training model...
train 1604/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 28m 58s
Starting training model...
train 1605/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 28m 12s
Starting training model...
train 1607/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 27m 41s
Starting training model...
train 1608/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 26m 43s
Starting training model...
train 1610/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 26m 23s
Starting training model...
train 1611/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 25m 38s
Starting training model...
train 1613/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 25m 6s
Starting training model...
train 1614/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 24m 9s
Starting training model...
train 1616/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 23m 49s
Starting training model...
train 1617/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 23m 3s
Starting training model...
train 1619/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 22m 32s
Starting training model...
train 1620/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('q_with_pos', True), ('learning_rate', 0.1), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 55/64
Starting batch load...
batch 55/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 20m 29s
Starting training model...
train 1622/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 20m 9s
Starting training model...
train 1623/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 19m 23s
Starting training model...
train 1625/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 18m 52s
Starting training model...
train 1626/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 17m 55s
Starting training model...
train 1628/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 17m 34s
Starting training model...
train 1629/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 16m 48s
Starting training model...
train 1631/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 16m 17s
Starting training model...
train 1632/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('attention_type', 'Cosine'), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 15m 20s
Starting training model...
train 1634/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 14m 59s
Starting training model...
train 1635/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 14m 13s
Starting training model...
train 1637/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 13m 42s
Starting training model...
train 1638/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 12m 46s
Starting training model...
train 1640/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 12m 25s
Starting training model...
train 1641/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 11m 38s
Starting training model...
train 1643/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 11m 7s
Starting training model...
train 1644/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 10m 11s
Starting training model...
train 1646/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 9m 50s
Starting training model...
train 1647/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 9m 3s
Starting training model...
train 1649/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 8m 33s
Starting training model...
train 1650/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 56/64
Starting batch load...
batch 56/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 6m 25s
Starting training model...
train 1652/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 6m 3s
Starting training model...
train 1653/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 5m 16s
Starting training model...
train 1655/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 4m 46s
Starting training model...
train 1656/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 3m 50s
Starting training model...
train 1658/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 3m 28s
Starting training model...
train 1659/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 2m 41s
Starting training model...
train 1661/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 2m 11s
Starting training model...
train 1662/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('attention_type', 'Cosine'), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 1m 15s
Starting training model...
train 1664/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 0m 54s
Starting training model...
train 1665/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2h 0m 6s
Starting training model...
train 1667/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 59m 36s
Starting training model...
train 1668/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 58m 40s
Starting training model...
train 1670/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 58m 19s
Starting training model...
train 1671/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 57m 31s
Starting training model...
train 1673/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 57m 1s
Starting training model...
train 1674/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 56m 6s
Starting training model...
train 1676/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 55m 44s
Starting training model...
train 1677/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 54m 56s
Starting training model...
train 1679/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': True, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 54m 26s
Starting training model...
train 1680/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_ner', True), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('learning_rate', 0.1), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 57/64
Starting batch load...
batch 57/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 51m 52s
Starting training model...
train 1682/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 51m 30s
Starting training model...
train 1683/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 50m 42s
Starting training model...
train 1685/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 50m 12s
Starting training model...
train 1686/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 49m 17s
Starting training model...
train 1688/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 48m 55s
Starting training model...
train 1689/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 48m 7s
Starting training model...
train 1691/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 47m 38s
Starting training model...
train 1692/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 46m 42s
Starting training model...
train 1694/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 46m 20s
Starting training model...
train 1695/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 45m 33s
Starting training model...
train 1697/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 45m 3s
Starting training model...
train 1698/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 44m 8s
Starting training model...
train 1700/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 43m 46s
Starting training model...
train 1701/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 42m 58s
Starting training model...
train 1703/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 42m 29s
Starting training model...
train 1704/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 41m 33s
Starting training model...
train 1706/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 41m 11s
Starting training model...
train 1707/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 40m 23s
Starting training model...
train 1709/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 39m 53s
Starting training model...
train 1710/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 58/64
Starting batch load...
batch 58/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 37m 24s
Starting training model...
train 1712/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 37m 1s
Starting training model...
train 1713/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 36m 13s
Starting training model...
train 1715/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 35m 44s
Starting training model...
train 1716/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 34m 49s
Starting training model...
train 1718/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 34m 26s
Starting training model...
train 1719/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 33m 37s
Starting training model...
train 1721/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 33m 8s
Starting training model...
train 1722/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('attention_type', 'Cosine'), ('q_with_ner', False), ('doc_hidden_layers', 1), ('befaft', False), ('hidden_size', 100), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 32m 14s
Starting training model...
train 1724/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('hidden_size', 100), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 31m 51s
Starting training model...
train 1725/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('hidden_size', 100), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 31m 2s
Starting training model...
train 1727/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('hidden_size', 100), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 30m 33s
Starting training model...
train 1728/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('hidden_size', 100), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 29m 39s
Starting training model...
train 1730/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 29m 16s
Starting training model...
train 1731/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 28m 27s
Starting training model...
train 1733/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 27m 58s
Starting training model...
train 1734/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 27m 4s
Starting training model...
train 1736/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 26m 41s
Starting training model...
train 1737/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 25m 52s
Starting training model...
train 1739/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 25m 23s
Starting training model...
train 1740/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 59/64
Starting batch load...
batch 59/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 23m 1s
Starting training model...
train 1742/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 22m 38s
Starting training model...
train 1743/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 21m 49s
Starting training model...
train 1745/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 21m 21s
Starting training model...
train 1746/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 20m 26s
Starting training model...
train 1748/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 20m 3s
Starting training model...
train 1749/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 19m 14s
Starting training model...
train 1751/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 18m 45s
Starting training model...
train 1752/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 17m 51s
Starting training model...
train 1754/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 17m 28s
Starting training model...
train 1755/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 16m 38s
Starting training model...
train 1757/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 16m 10s
Starting training model...
train 1758/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 15m 16s
Starting training model...
train 1760/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 14m 52s
Starting training model...
train 1761/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 14m 3s
Starting training model...
train 1763/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 13m 35s
Starting training model...
train 1764/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 12m 41s
Starting training model...
train 1766/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 12m 17s
Starting training model...
train 1767/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 11m 27s
Starting training model...
train 1769/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 10m 59s
Starting training model...
train 1770/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 60/64
Starting batch load...
batch 60/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 8m 42s
Starting training model...
train 1772/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 8m 18s
Starting training model...
train 1773/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 7m 28s
Starting training model...
train 1775/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 7m 0s
Starting training model...
train 1776/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 6m 7s
Starting training model...
train 1778/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 5m 43s
Starting training model...
train 1779/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 4m 53s
Starting training model...
train 1781/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 4m 25s
Starting training model...
train 1782/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('attention_type', 'Cosine'), ('q_with_ner', False), ('doc_hidden_layers', 1), ('befaft', False), ('hidden_size', 100), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 3m 31s
Starting training model...
train 1784/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('hidden_size', 100), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 3m 8s
Starting training model...
train 1785/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('hidden_size', 100), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 2m 18s
Starting training model...
train 1787/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('hidden_size', 100), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1h 1m 50s
Starting training model...
train 1788/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('hidden_size', 100), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 0m 56s
Starting training model...
train 1790/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 0m 32s
Starting training model...
train 1791/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 59m 42s
Starting training model...
train 1793/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 59m 14s
Starting training model...
train 1794/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 58m 21s
Starting training model...
train 1796/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 57m 57s
Starting training model...
train 1797/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 57m 6s
Starting training model...
train 1799/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': True, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 56m 39s
Starting training model...
train 1800/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_with_wm', True), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 61/64
Starting batch load...
batch 61/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 54m 27s
Starting training model...
train 1802/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 54m 3s
Starting training model...
train 1803/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 53m 13s
Starting training model...
train 1805/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 52m 45s
Starting training model...
train 1806/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 51m 52s
Starting training model...
train 1808/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 51m 28s
Starting training model...
train 1809/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 50m 37s
Starting training model...
train 1811/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 50m 10s
Starting training model...
train 1812/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('attention_type', 'Cosine'), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 49m 17s
Starting training model...
train 1814/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 48m 52s
Starting training model...
train 1815/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 48m 2s
Starting training model...
train 1817/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 47m 35s
Starting training model...
train 1818/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 46m 41s
Starting training model...
train 1820/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 46m 17s
Starting training model...
train 1821/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 45m 26s
Starting training model...
train 1823/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 44m 59s
Starting training model...
train 1824/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 44m 6s
Starting training model...
train 1826/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 43m 41s
Starting training model...
train 1827/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 42m 51s
Starting training model...
train 1829/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 42m 24s
Starting training model...
train 1830/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 62/64
Starting batch load...
batch 62/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 40m 16s
Starting training model...
train 1832/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 39m 51s
Starting training model...
train 1833/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 39m 1s
Starting training model...
train 1835/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 38m 34s
Starting training model...
train 1836/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 37m 41s
Starting training model...
train 1838/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 37m 16s
Starting training model...
train 1839/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 36m 25s
Starting training model...
train 1841/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 35m 58s
Starting training model...
train 1842/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('attention_type', 'Cosine'), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 35m 5s
Starting training model...
train 1844/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 34m 40s
Starting training model...
train 1845/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 33m 50s
Starting training model...
train 1847/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 33m 23s
Starting training model...
train 1848/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 32m 30s
Starting training model...
train 1850/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 32m 5s
Starting training model...
train 1851/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 31m 14s
Starting training model...
train 1853/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 30m 47s
Starting training model...
train 1854/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 29m 55s
Starting training model...
train 1856/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 29m 29s
Starting training model...
train 1857/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 28m 38s
Starting training model...
train 1859/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('attention_type', 'Scaled Dot Product'), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': True, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 28m 12s
Starting training model...
train 1860/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('q_with_pos', True), ('doc_with_ner', False), ('doc_with_pos', False), ('hidden_type', 'RNN'), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 63/64
Starting batch load...
batch 63/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 26m 9s
Starting training model...
train 1862/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 25m 44s
Starting training model...
train 1863/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 24m 52s
Starting training model...
train 1865/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 24m 26s
Starting training model...
train 1866/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 23m 33s
Starting training model...
train 1868/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 23m 8s
Starting training model...
train 1869/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 22m 17s
Starting training model...
train 1871/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 21m 50s
Starting training model...
train 1872/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('attention_type', 'Cosine'), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 20m 58s
Starting training model...
train 1874/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 20m 33s
Starting training model...
train 1875/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 19m 41s
Starting training model...
train 1877/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 19m 15s
Starting training model...
train 1878/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 18m 23s
Starting training model...
train 1880/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 17m 57s
Starting training model...
train 1881/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 17m 6s
Starting training model...
train 1883/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 16m 39s
Starting training model...
train 1884/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 15m 47s
Starting training model...
train 1886/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 15m 22s
Starting training model...
train 1887/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 14m 30s
Starting training model...
train 1889/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': True, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 14m 4s
Starting training model...
train 1890/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('q_with_ner', True), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
Starting load...
load 64/64
Starting batch load...
batch 64/64
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 12m 5s
Starting training model...
train 1892/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 11m 39s
Starting training model...
train 1893/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 10m 48s
Starting training model...
train 1895/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 1e-05, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 10m 21s
Starting training model...
train 1896/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('learning_rate', 1e-05), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 9m 29s
Starting training model...
train 1898/1920
frozenset({('answer_type', 'Out_And_In'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 9m 4s
Starting training model...
train 1899/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 8m 12s
Starting training model...
train 1901/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.0001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 7m 46s
Starting training model...
train 1902/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('learning_rate', 0.0001), ('attention_type', 'Cosine'), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('doc_hidden_layers', 1), ('q_with_ner', False), ('hidden_size', 100), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6m 54s
Starting training model...
train 1904/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 6m 28s
Starting training model...
train 1905/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5m 37s
Starting training model...
train 1907/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.001, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 5m 10s
Starting training model...
train 1908/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('learning_rate', 0.001), ('befaft', False), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 4m 19s
Starting training model...
train 1910/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3m 53s
Starting training model...
train 1911/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('bidirectional', True), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 3m 1s
Starting training model...
train 1913/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.01, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 2m 35s
Starting training model...
train 1914/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.01), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1m 43s
Starting training model...
train 1916/1920
frozenset({('answer_type', 'Out_And_In'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': True, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 1m 17s
Starting training model...
train 1917/1920
frozenset({('answer_type', 'Out_And_In'), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('bidirectional', True), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
skipping at training.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Scaled Dot Product', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 25s
Starting training model...
train 1919/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('attention_type', 'Scaled Dot Product'), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
[{'q_cut_size': 'Max', 'doc_cut_size': 256, 'answer_type': 'Out_And_In', 'befaft': False, 'doc_with_pos': False, 'doc_with_tfidf': False, 'doc_with_ner': False, 'doc_with_wm': False, 'q_with_pos': False, 'q_with_ner': False, 'batch': 128, 'learning_rate': 0.1, 'bidirectional': False, 'attention_type': 'Cosine', 'hidden_type': 'RNN', 'doc_hidden_layers': 1, 'hidden_size': 100, 'iters_inc': (1, 4, 5, 10)}]
Expected time 0s
Starting training model...
train 1920/1920
frozenset({('answer_type', 'Out_And_In'), ('bidirectional', False), ('attention_type', 'Cosine'), ('doc_hidden_layers', 1), ('q_cut_size', 'Max'), ('doc_with_tfidf', False), ('hidden_size', 100), ('q_with_ner', False), ('befaft', False), ('learning_rate', 0.1), ('iters_inc', (1, 4, 5, 10)), ('doc_with_wm', False), ('hidden_type', 'RNN'), ('doc_with_ner', False), ('doc_with_pos', False), ('q_with_pos', False), ('doc_cut_size', 256), ('batch', 128)})
Trained on 1.
Trained on 5.
Trained on 10.
Trained on 20.
