{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af1d613a-d52e-4d9d-bb2c-e03e5078358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when not using colab\n",
    "import sys\n",
    "sys.path.append('../src/QA')\n",
    "import reload_recursive\n",
    "%reload word_embed\n",
    "from word_embed import WordEmbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e790ea-3aab-4b8a-902b-3af0d11f57ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload data_prep\n",
    "from data_prep import DataPrep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c3d4da-a929-47d1-a306-8459634976d1",
   "metadata": {},
   "source": [
    "All these functions should be moved to their own module, im just doing it like this as a rough draft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "066e7459-7884-4f79-8a1a-0443fa07d48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e2f1e62-029c-456a-943a-e8b5504843ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataPrep.parse_tsv('../WikiQA-train.tsv')\n",
    "question_doc_raw_train = DataPrep.convert_pd_to_json(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e2e77d6-baa1-48ec-b0b6-16ee0669cabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/max/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /home/max/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/max/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/max/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%reload feat_extract\n",
    "from feat_extract import FeatExt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa428813-3fad-4400-b403-e65b153a3f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload embed_doc\n",
    "from embed_doc import EmbedAndConcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4f0a5c92-21ef-4015-8b91-bf1f8d6443f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_q_inputs, train_doc_inputs, train_doc_targets = EmbedAndConcat.get_unrolled_embeddings(question_doc_raw_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b522e2d5-2a4e-4ed9-a089-aebee77ae16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = DataPrep.parse_tsv('../WikiQA-test.tsv')\n",
    "question_doc_raw_test = DataPrep.convert_pd_to_json(df_test)\n",
    "test_q_inputs, test_doc_inputs, test_doc_targets = get_unrolled_embeddings(question_doc_raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d287311c-c942-4fe7-986e-9f4922b36336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question max len: 27\n",
      "Document max len: 1889\n",
      "After padding train question min len 27\n",
      "After padding test doc min len 256\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "q_max_len = max(get_max(train_q_inputs), get_max(test_q_inputs))\n",
    "doc_max_len = max(get_max(train_doc_inputs), get_max(test_doc_inputs))\n",
    "\n",
    "print(f\"question max len: {q_max_len}\")\n",
    "print(f\"Document max len: {doc_max_len}\")\n",
    "def cut(desired_size, lizt):\n",
    "    for elt in lizt:\n",
    "        if len(elt) > desired_size:\n",
    "            del elt[desired_size:]\n",
    "\n",
    "def pad(desired_size, lizt, target=False):\n",
    "    # embedding size for all should be the same.\n",
    "    if not target:\n",
    "        emb_size = np.shape(lizt[0][0])[0]\n",
    "    for i,_ in enumerate(lizt):\n",
    "        elt_len = len(lizt[i])\n",
    "        if elt_len < desired_size:\n",
    "            if target: # append empty answer to target\n",
    "                lizt[i].extend(['OOA'] * (desired_size - elt_len))\n",
    "            else: # pad empty arrays\n",
    "                lizt[i].extend([np.array([0] * emb_size) for x in range(elt_len, desired_size)])\n",
    "\n",
    "def cut_pad_to(desired_size, lizt, target=False):\n",
    "    cut(desired_size, lizt)\n",
    "    pad(desired_size, lizt, target=target)\n",
    "\n",
    "\n",
    "doc_len = 256\n",
    "import copy\n",
    "train_q_cop = copy.deepcopy(train_q_inputs)\n",
    "test_q_cop = copy.deepcopy(test_q_inputs)\n",
    "train_doc_cop = copy.deepcopy(train_doc_inputs)\n",
    "test_doc_cop = copy.deepcopy(test_doc_inputs)\n",
    "train_doc_targets_cop = copy.deepcopy(train_doc_targets)\n",
    "test_doc_targets_cop = copy.deepcopy(test_doc_targets)\n",
    "cut_pad_to(q_max_len, train_q_cop)\n",
    "cut_pad_to(q_max_len, test_q_cop)\n",
    "cut_pad_to(doc_len, train_doc_cop)\n",
    "cut_pad_to(doc_len, test_doc_cop)\n",
    "cut_pad_to(doc_len, train_doc_targets_cop, target=True)\n",
    "cut_pad_to(doc_len, test_doc_targets_cop, target=True)\n",
    "print(f\"After padding train question min len {get_min(train_q_cop)}\")\n",
    "print(f\"After padding test doc min len {get_min(test_doc_cop)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "955788e7-8f08-48d8-b26e-221d625030e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the target tags into integers\n",
    "# only OOA and IOA for now\n",
    "target2int = {\"OOA\": 0, \"IOA\": 1, \"BOA\": 1, \"EOA\": 1}\n",
    "int2target = {0: \"OOA\", 1: \"IOA\", 2: \"BOA\", 3: \"EOA\"}\n",
    "def convert_targets(raw_target_list):\n",
    "    for i, targets in enumerate(raw_target_list):\n",
    "        for j, _ in enumerate(targets):\n",
    "            raw_target_list[i][j] = target2int[raw_target_list[i][j]]\n",
    "            \n",
    "convert_targets(train_doc_targets_cop)\n",
    "convert_targets(test_doc_targets_cop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf57a037-ebbc-4331-83af-fb160bef6db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 17.082546461579525]\n"
     ]
    }
   ],
   "source": [
    "# returns ratios of the number of class instances\n",
    "def get_class_weights(raw_targets, classes):\n",
    "    freqs = [0]*classes\n",
    "    for i, targets in enumerate(raw_targets):\n",
    "        for j, _ in enumerate(targets):\n",
    "            freqs[raw_targets[i][j]] += 1\n",
    "    biggest_class = max(freqs)\n",
    "    return [biggest_class/x for x in freqs]\n",
    "\n",
    "training_class_weights = get_class_weights(train_doc_targets_cop, 2)\n",
    "print(training_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "773341b8-76de-4021-bd98-ddaa64c37e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33889/2486513719.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525493953/work/torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  train_dataset = TensorDataset(torch.Tensor(train_q_cop), torch.Tensor(train_doc_cop), torch.LongTensor(train_doc_targets_cop))\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "import torch\n",
    "train_dataset = TensorDataset(torch.Tensor(train_q_cop), torch.Tensor(train_doc_cop), torch.LongTensor(train_doc_targets_cop))\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True) \n",
    "\n",
    "test_question_tensor = torch.Tensor(test_q_cop)\n",
    "test_doc_tensor = torch.Tensor(test_doc_cop)\n",
    "test_target_tensor = torch.LongTensor(test_doc_targets_cop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6b3229e-5204-4be0-b97f-34e5ee4cf089",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_embed_size = np.shape(train_q_cop[0][0])[0]\n",
    "doc_embed_size = np.shape(train_doc_cop[0][0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26545970-86b7-4db9-9186-3ceb4f6df4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_q_inputs\n",
    "del test_q_inputs\n",
    "del train_doc_inputs\n",
    "del test_doc_inputs\n",
    "del train_doc_targets\n",
    "del test_doc_targets\n",
    "del train_q_cop\n",
    "del test_q_cop\n",
    "del train_doc_cop\n",
    "del test_doc_cop\n",
    "del train_doc_targets_cop\n",
    "del test_doc_targets_cop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "231f77c4-0b9b-4077-8130-f4e441ff5dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32108bfc-758a-477b-ba7a-7b1633980377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_question_tensor, input_document_tensor, target_tensor, question_model, document_model, question_optimizer, document_optimizer, criterion):\n",
    "    loss = 0    \n",
    "\n",
    "    question_optimizer.zero_grad()\n",
    "    document_optimizer.zero_grad()\n",
    "    # get output from question model\n",
    "    question_output = question_model(input_question_tensor)\n",
    "\n",
    "    # predictions from the document model with output from question for attention\n",
    "    document_output = document_model(input_document_tensor, question_output)\n",
    "    \n",
    "    loss = criterion(document_output.view(-1, document_output.shape[-1]), target_tensor.view(-1))\n",
    "    loss.backward()\n",
    "    \n",
    "    question_optimizer.step()\n",
    "    document_optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e684cb0-505a-4a1e-a353-bc4c06fa09f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "# Helper functions for training\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "580cf374-e040-4703-9b47-945256242b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def trainIters(question_model, document_model, n_iters, class_balance=None, print_every=5, plot_every=10, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    question_model_optimizer = optim.SGD(question_model.parameters(), lr=learning_rate)\n",
    "    document_model_optimizer = optim.SGD(document_model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.NLLLoss(weight=class_balance)\n",
    "    \n",
    "    for iter in range(1, n_iters):\n",
    "        for question_input,doc_input,targets in train_loader:\n",
    "            question_input = question_input.to(device)\n",
    "            doc_input = doc_input.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            loss = train(question_input, doc_input, targets, question_model, document_model, question_model_optimizer, document_model_optimizer, criterion)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0f77bdb-3236-4070-83e2-9e2be5d812fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload model.QA_RNN\n",
    "from model import QA_RNN\n",
    "hidden_size = 100\n",
    "doc_rnn_model = QA_RNN.DocumentModel(doc_embed_size, hidden_size, 2).to(device)\n",
    "question_rnn_model = QA_RNN.QuestionModel(q_embed_size, hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f945f807-f321-4008-80cc-b1e754e21dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 9s (- 0m 46s) (5 16%) 11.4348\n",
      "0m 18s (- 0m 37s) (10 33%) 10.9692\n",
      "0m 28s (- 0m 28s) (15 50%) 10.6623\n",
      "0m 37s (- 0m 18s) (20 66%) 10.4199\n",
      "0m 46s (- 0m 9s) (25 83%) 10.2434\n"
     ]
    }
   ],
   "source": [
    "trainIters(question_rnn_model, doc_rnn_model, 30, torch.Tensor(training_class_weights))\n",
    "#trainIters(question_rnn_model, doc_rnn_model, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bb0a819-cf73-4711-8b33-257f8557f973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def evaluate(input_question_tensor, input_document_tensor, target_tensor, question_model, document_model):\n",
    "    with torch.no_grad():\n",
    "        loss = 0\n",
    "        \n",
    "        question_output = question_model(input_question_tensor)\n",
    "        \n",
    "        document_output = document_model(input_document_tensor, question_output)\n",
    "        predicts = torch.argmax(document_output.view(-1, document_output.shape[-1]), dim=-1)\n",
    "        print(sum(predicts==0))\n",
    "        print(classification_report(predicts, target_tensor.view(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34ca361a-24f4-4b71-843f-a45faf307147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(56328)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.99      0.53     56328\n",
      "           1       0.93      0.07      0.14    104952\n",
      "\n",
      "    accuracy                           0.39    161280\n",
      "   macro avg       0.65      0.53      0.34    161280\n",
      "weighted avg       0.73      0.39      0.28    161280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(test_question_tensor, test_doc_tensor, test_target_tensor, question_rnn_model, doc_rnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43616da-f7e9-4517-b499-777430265a07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
