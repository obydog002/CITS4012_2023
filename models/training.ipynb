{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af1d613a-d52e-4d9d-bb2c-e03e5078358e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/max/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# when not using colab\n",
    "import sys\n",
    "sys.path.append('../src/QA')\n",
    "import reload_recursive\n",
    "%reload word_embed\n",
    "from word_embed import WordEmbed\n",
    "%reload embed_doc\n",
    "from embed_doc import EmbedAndConcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e790ea-3aab-4b8a-902b-3af0d11f57ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload data_prep\n",
    "from data_prep import DataPrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "02d0463f-c82a-4750-b3e4-28de0904ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload model.QA_RNN\n",
    "from model.QA_RNN import DocumentModel\n",
    "from model.QA_RNN import QuestionModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c3d4da-a929-47d1-a306-8459634976d1",
   "metadata": {},
   "source": [
    "All these functions should be moved to their own module, im just doing it like this as a rough draft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066e7459-7884-4f79-8a1a-0443fa07d48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e2f1e62-029c-456a-943a-e8b5504843ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataPrep.parse_tsv('../WikiQA-train.tsv')\n",
    "question_doc_raw_train = DataPrep.convert_pd_to_json(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f0a5c92-21ef-4015-8b91-bf1f8d6443f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO - add to package somwhere\n",
    "def get_unrolled_embeddings(df):\n",
    "    q_inputs = []\n",
    "    doc_inputs = []\n",
    "    doc_targets = []\n",
    "    for key in df.keys():\n",
    "        toks = DataPrep.tokenize_question_and_doc(df[key])\n",
    "        q_embeds = EmbedAndConcat.q_concat(toks[0])\n",
    "        doc_embeds = EmbedAndConcat.doc_concat(toks[1])\n",
    "        # toks[2] are the targets\n",
    "        # unroll the document and tokens.\n",
    "        # that is, create from [[sent1_word1_embed, sent1_word2_embed,...], [sent2_word1_embed...]]\n",
    "        # simply [word1_embed, word2_embed...]\n",
    "        unrolled_doc_embeds = [word_embed for sentence in doc_embeds for word_embed in sentence]\n",
    "        unrolled_doc_targets = [target for sentence in toks[2] for target in sentence]\n",
    "        q_inputs.append(q_embeds)\n",
    "        doc_inputs.append(unrolled_doc_embeds)\n",
    "        doc_targets.append(unrolled_doc_targets)\n",
    "    return q_inputs, doc_inputs, doc_targets\n",
    "\n",
    "train_q_inputs, train_doc_inputs, train_doc_targets = get_unrolled_embeddings(question_doc_raw_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "032220c8-5653-413b-928f-cfa54ac06da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max(l):\n",
    "    return max(len(item) for item in l)\n",
    "def get_min(l):\n",
    "    return min(len(item) for item in l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1514503d-bf18-4feb-9676-4ba321894189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "1064\n",
      "1064\n"
     ]
    }
   ],
   "source": [
    "print(get_max(train_q_inputs))\n",
    "print(get_max(train_doc_inputs))\n",
    "print(get_max(train_doc_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cab38fd-3014-4045-b38e-28f6f396f5b4",
   "metadata": {},
   "source": [
    "Now do the same for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b522e2d5-2a4e-4ed9-a089-aebee77ae16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = DataPrep.parse_tsv('../WikiQA-test.tsv')\n",
    "question_doc_raw_test = DataPrep.convert_pd_to_json(df_test)\n",
    "test_q_inputs, test_doc_inputs, test_doc_targets = get_unrolled_embeddings(question_doc_raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d82e6755-1ba0-4da0-8a85-a08094dacb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "1889\n",
      "1889\n"
     ]
    }
   ],
   "source": [
    "print(get_max(test_q_inputs))\n",
    "print(get_max(test_doc_inputs))\n",
    "print(get_max(test_doc_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01de8740-eab4-4c7b-97b7-61953554a06b",
   "metadata": {},
   "source": [
    "apply padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d287311c-c942-4fe7-986e-9f4922b36336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question max len: 27\n",
      "Document max len: 1889\n",
      "After padding train question min len 27\n",
      "After padding test doc min len 1889\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "q_max_len = max(get_max(train_q_inputs), get_max(test_q_inputs))\n",
    "doc_max_len = max(get_max(train_doc_inputs), get_max(test_doc_inputs))\n",
    "\n",
    "print(f\"question max len: {q_max_len}\")\n",
    "print(f\"Document max len: {doc_max_len}\")\n",
    "def cut(desired_size, lizt):\n",
    "    for elt in lizt:\n",
    "        del elt[desired_size:]\n",
    "\n",
    "def pad(desired_size, lizt, target=False):\n",
    "    # embedding size for all should be the same.\n",
    "    if not target:\n",
    "        emb_size = np.shape(lizt[0][0])[0]\n",
    "    for i,_ in enumerate(lizt):\n",
    "        elt_len = len(lizt[i])\n",
    "        if elt_len < desired_size:\n",
    "            if target: # append empty answer to target\n",
    "                lizt[i].extend(['OOA'] * (desired_size - elt_len))\n",
    "            else: # pad empty arrays\n",
    "                lizt[i].extend([np.array([0] * emb_size) for x in range(elt_len, desired_size)])\n",
    "\n",
    "import copy\n",
    "train_q_cop = copy.deepcopy(train_q_inputs)\n",
    "test_q_cop = copy.deepcopy(test_q_inputs)\n",
    "train_doc_cop = copy.deepcopy(train_doc_inputs)\n",
    "test_doc_cop = copy.deepcopy(test_doc_inputs)\n",
    "train_doc_targets_cop = copy.deepcopy(train_doc_targets)\n",
    "test_doc_targets_cop = copy.deepcopy(test_doc_targets)\n",
    "pad(q_max_len, train_q_cop)\n",
    "pad(q_max_len, test_q_cop)\n",
    "pad(doc_max_len, train_doc_cop)\n",
    "pad(doc_max_len, test_doc_cop)\n",
    "pad(doc_max_len, train_doc_targets_cop, target=True)\n",
    "pad(doc_max_len, test_doc_targets_cop, target=True)\n",
    "print(f\"After padding train question min len {get_min(train_q_cop)}\")\n",
    "print(f\"After padding test doc min len {get_min(test_doc_cop)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "955788e7-8f08-48d8-b26e-221d625030e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the target tags into integers\n",
    "target2int = {\"OOA\": 0, \"IOA\": 1, \"BOA\": 2, \"EOA\": 3}\n",
    "int2target = {0: \"OOA\", 1: \"IOA\", 2: \"BOA\", 3: \"EOA\"}\n",
    "for i, targets in enumerate(train_doc_targets_cop):\n",
    "    for j, _ in enumerate(targets):\n",
    "        train_doc_targets_cop[i][j] = target2int[train_doc_targets_cop[i][j]]\n",
    "    \n",
    "for i, targets in enumerate(test_doc_targets_cop):\n",
    "    for j, _ in enumerate(targets):\n",
    "        test_doc_targets_cop[i][j] = target2int[test_doc_targets_cop[i][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "773341b8-76de-4021-bd98-ddaa64c37e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4203/2374604515.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525493953/work/torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  train_dataset = TensorDataset(torch.Tensor(train_q_cop), torch.Tensor(train_doc_cop), torch.Tensor(train_doc_targets_cop))\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "import torch\n",
    "train_dataset = TensorDataset(torch.Tensor(train_q_cop), torch.Tensor(train_doc_cop), torch.Tensor(train_doc_targets_cop))\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "#More detailed info about the dataLoader, https://pytorch.org/docs/1.1.0/_modules/torch/utils/data/dataloader.html\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True) \n",
    "# shuffle (bool, optional) â€“ set to True to have the data reshuffled at every epoch (default: False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6b3229e-5204-4be0-b97f-34e5ee4cf089",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_embed_size = np.shape(train_q_cop[0][0])[0]\n",
    "doc_embed_size = np.shape(train_doc_cop[0][0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26545970-86b7-4db9-9186-3ceb4f6df4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_q_inputs\n",
    "del test_q_inputs\n",
    "del train_doc_inputs\n",
    "del test_doc_inputs\n",
    "del train_doc_targets\n",
    "del test_doc_targets\n",
    "del train_q_cop\n",
    "del test_q_cop\n",
    "del train_doc_cop\n",
    "del test_doc_cop\n",
    "del train_doc_targets_cop\n",
    "del test_doc_targets_cop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "231f77c4-0b9b-4077-8130-f4e441ff5dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "50d63183-464e-4cd2-b1ac-3d560c713446",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_rnn_model = QA_RNN.DocumentModel(doc_embed_size, doc_embed_size, doc_embed_size)\n",
    "question_rnn_model = QA_RNN.QuestionModel(q_embed_size, q_embed_size, doc_embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "32108bfc-758a-477b-ba7a-7b1633980377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_question_tensor, input_document_tensor, target_tensor, question_model, document_model, question_optimizer, document_optimizer, criterion):\n",
    "    loss = 0    \n",
    "    question_optimizer.zero_grad()\n",
    "    document_optimizer.zero_grad()\n",
    "\n",
    "    # get output from question model\n",
    "    question_output = question_model(input_question_tensor)\n",
    "\n",
    "    # predictions from the document model with output from question for attention\n",
    "    document_output = document_model(input_document_tensor, question_output)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3e684cb0-505a-4a1e-a353-bc4c06fa09f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "# Helper functions for training\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "580cf374-e040-4703-9b47-945256242b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def trainIters(question_model, document_model, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    question_model_optimizer = optim.SGD(question_model.parameters(), lr=learning_rate)\n",
    "    document_model_optimizer = optim.SGD(document_model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for question_input,doc_input,targets in train_loader:\n",
    "        question_input = question_input.to(device)\n",
    "        doc_input = doc_input.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        print(\"qweqweq\")\n",
    "        loss = train(question_input, doc_input, targets, question_model, document_model, question_model_optimizer, document_model_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f945f807-f321-4008-80cc-b1e754e21dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qweqweq\n",
      "torch.Size([128, 102])\n",
      "torch.Size([128, 102])\n",
      "torch.Size([128, 1, 1])\n",
      "torch.Size([1, 128, 102])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[128, 1, 1]' is invalid for input of size 13056",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainIters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion_rnn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_rnn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[79], line 19\u001b[0m, in \u001b[0;36mtrainIters\u001b[0;34m(question_model, document_model, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     16\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqweqweq\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocument_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion_model_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocument_model_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m print_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     21\u001b[0m plot_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "Cell \u001b[0;32mIn[77], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(input_question_tensor, input_document_tensor, target_tensor, question_model, document_model, question_optimizer, document_optimizer, criterion)\u001b[0m\n\u001b[1;32m      7\u001b[0m question_output \u001b[38;5;241m=\u001b[39m question_model(input_question_tensor)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# predictions from the document model with output from question for attention\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m document_output \u001b[38;5;241m=\u001b[39m \u001b[43mdocument_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_document_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     14\u001b[0m encoder_optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/school/CITS4012/project/models/../src/QA/model/QA_RNN.py:39\u001b[0m, in \u001b[0;36mDocumentModel.forward\u001b[0;34m(self, input, question_hidden)\u001b[0m\n\u001b[1;32m     36\u001b[0m rnn_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((h_n[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:,:],h_n[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m,:,:]),\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     37\u001b[0m hidden_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn_to_att(rnn_out)\n\u001b[0;32m---> 39\u001b[0m catted_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDocumentModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mATTN_TYPE_DOT_PRODUCT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout(catted_output), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, hidden_out\n",
      "File \u001b[0;32m~/Documents/school/CITS4012/project/models/../src/QA/model/QA_RNN.py:28\u001b[0m, in \u001b[0;36mDocumentModel.calc_attention\u001b[0;34m(self, hidden, question_hidden, method)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m DocumentModel\u001b[38;5;241m.\u001b[39mATTN_TYPE_DOT_PRODUCT:\n\u001b[1;32m     27\u001b[0m     weights \u001b[38;5;241m=\u001b[39m  F\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdot(hidden, question_hidden), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion_hidden\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     catted_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((attention_output, hidden), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m catted_output\n",
      "File \u001b[0;32m~/Documents/school/CITS4012/project/models/../src/QA/model/QA_RNN.py:23\u001b[0m, in \u001b[0;36mDocumentModel.dot\u001b[0;34m(self, t1, t2)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(t1\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(t2\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbmm(t1\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m1\u001b[39m, layer_size), \u001b[43mt2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[128, 1, 1]' is invalid for input of size 13056"
     ]
    }
   ],
   "source": [
    "trainIters(question_rnn_model, doc_rnn_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00a41a0-f034-4fe1-b04c-84f51e12b36e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3876e04a-52c0-4028-b26e-9cd7ee8e38b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0c24a6-f55b-4e16-adc3-bf0700f0741b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c099075b-80a2-4fcc-a2c3-03a9e9e89c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
