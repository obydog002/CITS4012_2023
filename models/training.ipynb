{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af1d613a-d52e-4d9d-bb2c-e03e5078358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when not using colab\n",
    "import sys\n",
    "sys.path.append('../src/QA')\n",
    "import reload_recursive\n",
    "%reload word_embed\n",
    "from word_embed import WordEmbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7e790ea-3aab-4b8a-902b-3af0d11f57ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload data_prep\n",
    "from data_prep import DataPrep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c3d4da-a929-47d1-a306-8459634976d1",
   "metadata": {},
   "source": [
    "All these functions should be moved to their own module, im just doing it like this as a rough draft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "066e7459-7884-4f79-8a1a-0443fa07d48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e2f1e62-029c-456a-943a-e8b5504843ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataPrep.parse_tsv('../WikiQA-train.tsv')\n",
    "question_doc_raw_train = DataPrep.convert_pd_to_json(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e2e77d6-baa1-48ec-b0b6-16ee0669cabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/max/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /home/max/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/max/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/max/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/max/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /home/max/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/max/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/max/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%reload feat_extract\n",
    "from feat_extract import FeatExt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa428813-3fad-4400-b403-e65b153a3f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload embed_doc\n",
    "from embed_doc import EmbedAndConcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f0a5c92-21ef-4015-8b91-bf1f8d6443f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_q_inputs, train_doc_inputs, train_doc_targets = EmbedAndConcat.get_unrolled_embeddings(question_doc_raw_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b522e2d5-2a4e-4ed9-a089-aebee77ae16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = DataPrep.parse_tsv('../WikiQA-test.tsv')\n",
    "question_doc_raw_test = DataPrep.convert_pd_to_json(df_test)\n",
    "test_q_inputs, test_doc_inputs, test_doc_targets = EmbedAndConcat.get_unrolled_embeddings(question_doc_raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6dbf2ef4-1cf3-4754-89a4-436cdec15ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload pad\n",
    "from pad import Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d287311c-c942-4fe7-986e-9f4922b36336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After padding train question min len 27\n",
      "After padding test doc min len 1889\n"
     ]
    }
   ],
   "source": [
    "q_max_len = max(Pad.get_max(train_q_inputs), Pad.get_max(test_q_inputs))\n",
    "doc_max_len = max(Pad.get_max(train_doc_inputs), Pad.get_max(test_doc_inputs))\n",
    "\n",
    "doc_len = doc_max_len\n",
    "Pad.cut_pad_to(q_max_len, train_q_inputs)\n",
    "Pad.cut_pad_to(q_max_len, test_q_inputs)\n",
    "Pad.cut_pad_to(doc_len, train_doc_inputs)\n",
    "Pad.cut_pad_to(doc_len, test_doc_inputs)\n",
    "Pad.cut_pad_to(doc_len, train_doc_targets, target=True)\n",
    "Pad.cut_pad_to(doc_len, test_doc_targets, target=True)\n",
    "print(f\"After padding train question min len {Pad.get_min(train_q_inputs)}\")\n",
    "print(f\"After padding test doc min len {Pad.get_min(test_doc_inputs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "955788e7-8f08-48d8-b26e-221d625030e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the target tags into integers\n",
    "# only OOA and IOA for now\n",
    "target2int = {\"OOA\": 0, \"IOA\": 1, \"BOA\": 1, \"EOA\": 1}\n",
    "int2target = {0: \"OOA\", 1: \"IOA\", 2: \"BOA\", 3: \"EOA\"}\n",
    "\n",
    "Pad.convert_targets(train_doc_targets, target2int)\n",
    "Pad.convert_targets(test_doc_targets, target2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44b8d2a8-8583-4327-8883-b372f1c1f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload stat_helper\n",
    "from stat_helper import StatHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf57a037-ebbc-4331-83af-fb160bef6db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 122.84679467327346]\n"
     ]
    }
   ],
   "source": [
    "training_class_weights = StatHelper.get_class_weights(train_doc_targets, 2)\n",
    "print(training_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "773341b8-76de-4021-bd98-ddaa64c37e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35181/3378231814.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525493953/work/torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  train_dataset = TensorDataset(torch.Tensor(train_q_inputs), torch.Tensor(train_doc_inputs), torch.LongTensor(train_doc_targets))\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "import torch\n",
    "train_dataset = TensorDataset(torch.Tensor(train_q_inputs), torch.Tensor(train_doc_inputs), torch.LongTensor(train_doc_targets))\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True) \n",
    "\n",
    "test_question_tensor = torch.Tensor(test_q_inputs)\n",
    "test_doc_tensor = torch.Tensor(test_doc_inputs)\n",
    "test_target_tensor = torch.LongTensor(test_doc_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26545970-86b7-4db9-9186-3ceb4f6df4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_q_inputs\n",
    "del test_q_inputs\n",
    "del train_doc_inputs\n",
    "del test_doc_inputs\n",
    "del train_doc_targets\n",
    "del test_doc_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "231f77c4-0b9b-4077-8130-f4e441ff5dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7537"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32108bfc-758a-477b-ba7a-7b1633980377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_question_tensor, input_document_tensor, target_tensor, question_model, document_model, question_optimizer, document_optimizer, criterion):\n",
    "    loss = 0    \n",
    "\n",
    "    question_optimizer.zero_grad()\n",
    "    document_optimizer.zero_grad()\n",
    "    # get output from question model\n",
    "    question_output = question_model(input_question_tensor)\n",
    "\n",
    "    # predictions from the document model with output from question for attention\n",
    "    document_output = document_model(input_document_tensor, question_output)\n",
    "    \n",
    "    loss = criterion(document_output.view(-1, document_output.shape[-1]), target_tensor.view(-1))\n",
    "    loss.backward()\n",
    "    \n",
    "    question_optimizer.step()\n",
    "    document_optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e684cb0-505a-4a1e-a353-bc4c06fa09f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "# Helper functions for training\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "580cf374-e040-4703-9b47-945256242b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def trainIters(question_model, document_model, n_iters, class_balance=None, print_every=5, plot_every=10, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    question_model_optimizer = optim.SGD(question_model.parameters(), lr=learning_rate)\n",
    "    document_model_optimizer = optim.SGD(document_model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.NLLLoss(weight=class_balance)\n",
    "    \n",
    "    for iter in range(1, n_iters):\n",
    "        for question_input,doc_input,targets in train_loader:\n",
    "            question_input = question_input.to(device)\n",
    "            doc_input = doc_input.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            loss = train(question_input, doc_input, targets, question_model, document_model, question_model_optimizer, document_model_optimizer, criterion)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0f77bdb-3236-4070-83e2-9e2be5d812fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload model.QA_RNN\n",
    "from model import QA_RNN\n",
    "q_embed_size = list(train_loader)[0][0].shape[2]\n",
    "doc_embed_size = list(train_loader)[0][1].shape[2]\n",
    "hidden_size = 100\n",
    "doc_rnn_model = QA_RNN.DocumentModel(doc_embed_size, hidden_size, 2).to(device)\n",
    "question_rnn_model = QA_RNN.QuestionModel(q_embed_size, hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f945f807-f321-4008-80cc-b1e754e21dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 3s (- 5m 18s) (5 16%) 6.8757\n",
      "2m 7s (- 4m 14s) (10 33%) 4.4627\n",
      "3m 10s (- 3m 10s) (15 50%) 3.8020\n",
      "4m 14s (- 2m 7s) (20 66%) 3.5908\n",
      "5m 17s (- 1m 3s) (25 83%) 3.4949\n"
     ]
    }
   ],
   "source": [
    "trainIters(question_rnn_model, doc_rnn_model, 30, torch.Tensor(training_class_weights))\n",
    "#trainIters(question_rnn_model, doc_rnn_model, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8bb0a819-cf73-4711-8b33-257f8557f973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def evaluate(input_question_tensor, input_document_tensor, target_tensor, question_model, document_model):\n",
    "    with torch.no_grad():\n",
    "        loss = 0\n",
    "        \n",
    "        question_output = question_model(input_question_tensor)\n",
    "        \n",
    "        document_output = document_model(input_document_tensor, question_output)\n",
    "        predicts = torch.argmax(document_output.view(-1, document_output.shape[-1]), dim=-1)\n",
    "        print(classification_report(predicts, target_tensor.view(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34ca361a-24f4-4b71-843f-a45faf307147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1030667)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93   1030667\n",
      "           1       1.00      0.05      0.10    159403\n",
      "\n",
      "    accuracy                           0.87   1190070\n",
      "   macro avg       0.94      0.53      0.52   1190070\n",
      "weighted avg       0.89      0.87      0.82   1190070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(test_question_tensor, test_doc_tensor, test_target_tensor, question_rnn_model, doc_rnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43616da-f7e9-4517-b499-777430265a07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
